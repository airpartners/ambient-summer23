---
title: "API Call"
author: "Cherry Pham"
date: "2023-06-20"
output: html_document
editor_options: 
  markdown: 
    wrap: 72
---

This Markdown file is created with the purpose of obtaining sensor data
from Quant-AQ through API calls.

There is no prerequisites for using this file. If you are just looking
to quickly retrieve data, you can simply run this file through the
command `Ctrl + Alt + R`. The result of running this file is a data
folder containing data of MOD-PM sensors as of February 2023. If you
wish to modify the data to be retrieved, please read the data guide
below.

## DATA GUIDE

[write instructions here]

[sorry if i forgot to do this at the end, the code below is quite well
documented though so good luck]

## PACKAGES AND INITIAL SETTINGS

```{r}
# Check and install required packages if necessary
packages <- c("httr", "jsonlite", "purrr", "dplyr", "tidyverse", "tidyr")
install.packages(packages[!sapply(packages, requireNamespace, quietly = TRUE)])

# Load required packages
invisible(sapply(packages, library, character.only = TRUE))

# Explicit package function calls
httr::GET
httr::content
jsonlite::fromJSON
purrr::map_df
dplyr::as_data_frame
dplyr::filter
dplyr::lag

# Set options
knitr::opts_chunk$set(echo = FALSE, message = FALSE)
```

## DEFINE VARIABLES

```{r}
base_url <- "https://api.quant-aq.com/device-api/v1/devices/"
api_key <- "VUOLNUDTM70QZ7Z9G0Z78XA7"

# Define a time range to loop over until I find a better way
time_range <-
  seq(as.Date("2022-07-19"), as.Date("2022-07-20"), by = "day")
time_range <- format(time_range, "%Y-%m-%d")

# Define a list of device IDs
device_ids <- c(
  "MOD-00024",
  "MOD-00025",
  "MOD-00026",
  "MOD-00027",
  "MOD-00028",
  "MOD-PM-00141",
  "MOD-PM-00211",
  "MOD-PM-00212",
  "MOD-PM-00213",
  "MOD-PM-00214",
  "MOD-PM-00216",
  "MOD-PM-00217",
  "MOD-PM-00221",
  "MOD-PM-00222",
  "MOD-PM-00224",
  "MOD-PM-00226",
  "MOD-PM-00230",
  "MOD-PM-00231"
)
```

## RETTRIEVING DATA INTO FOLDERS

```{r}
# Create folder if not initiated
data_folder_path <- "./data/Quant-AQ/MOD-PM/"

# Check if the folder exists
if (!file.exists(data_folder_path)) {
  # Create the folder if it doesn't exist
  dir.create(data_folder_path, recursive = TRUE)
}

# Function to process a single device ID
process_device_id <- function(device_id, date, state) {
  for (date in time_range) {
    # Initialize data frames
    raw_df <- data.frame()
    final_df <- data.frame()
    merged_data_per_sensor <- data.frame()
    for (state in c("raw/", "")) {
      
      # Construct device URL for API call
      device_url <-
        paste0(device_id, "/data-by-date/", state, date, "/")
      
      # Send GET request
      raw_data <- GET(
        url = paste0(base_url, device_url),
        authenticate(api_key, "", type = "basic"),
        encoding = "UTF-8"
      )
      
      # Option 1: Simply ignore the faulty API responses
      # Option 2 in commit <1af8a62915811ba44d4f7e4b2cc6eab7c97240c1> gives u
      # detailed errors
      if (status_code(raw_data) != 200) {
        return()
      }
      
      data <- content(raw_data, as = "text", encoding = "UTF-8")
      parsed_data <- fromJSON(data)
      
      # Check if the data is empty or has zero rows
      if (is.null(parsed_data) ||
          is.null(parsed_data$data) ||
          length(parsed_data$data) == 0) {
        # Skip processing if the data is empty
        next
      }
      
      # Save raw and final data accordingly
      if (state == "raw/") {
        raw_df <- as.data.frame(parsed_data$data)
      } else {
        final_df <- as.data.frame(parsed_data$data)
      }
    }
    
    # Skip processing if the merged data is empty or has zero rows
    if (is.null(raw_df) ||
        is.null(final_df) ||
        nrow(raw_df) == 0 || nrow(final_df) == 0) {
      return()
    }
    # Merge raw and final data
    merged_data_per_day <-
      merge(raw_df, final_df, by = "timestamp_local")
  }
  # Skip processing if the merged data is empty or has zero rows
  if (is.null(merged_data_per_day) ||
      nrow(merged_data_per_day) == 0) {
    return()
  }
  
    # Initialize flag to track nested status
    is_nested <- TRUE
    
    # Flatten any nested dataframes
    while (is_nested) {
      # Check if the data frame is nested
      is_nested <-
        any(sapply(merged_data_per_day, function(x)
          is.list(x) || is.data.frame(x)))
      
      if (is_nested) {
        # Flatten any nested data frames
        cols_to_unnest <-
          names(merged_data_per_day)[sapply(merged_data_per_day, is.data.frame)]
        # Unnest with duplicate handling strategy
        merged_data_per_day <-
          unnest_wider(merged_data_per_day, cols_to_unnest, names_repair = "unique")
      }
      else {break}
    }
  
  merged_data_per_sensor <- rbind(merged_data_per_sensor, merged_data_per_day)
  # Check if the device folder exists
  if (!dir.exists(data_folder_path)) {
    # Create the device folder if it doesn't exist
    dir.create(data_folder_path, recursive = TRUE)
  }

  # Save data to CSV file
  csv_file_path <-
    file.path(data_folder_path, paste0(device_id, ".csv"))

  # Try writing the CSV file and handle errors
  tryCatch({
    write.csv(merged_data_per_day, file = csv_file_path)
  },
  error = function(e) {
    cat(
      paste0("Error writing CSV file for ", device_id, "\n"),
      file = "error_log.txt",
      append = TRUE
    )
  })
}

# Process each device ID over time range
for (device_id in device_ids) {
      process_device_id(device_id, date, state)
}
```
