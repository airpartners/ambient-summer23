---
title: "Data Breakdown"
author: "Cherry Pham"
date: "2023-07-10"
output: html_document
---
[Markdown file docstrings]

## INITAL SETTINGS

```{r}
# Check and install required packages if necessary
packages <- c(
  "lubridate",   # Package for working with dates and times
  "data.table",  # Package for efficient data manipulation and processing
  "dplyr",       # Package for data manipulation and transformation
  "openair",     # Package for analyzing air pollution data
  "openairmaps", # Package for accessing open air pollution data
  "stringr",     # Package for string manipulation
  "baseline",    # Package for baseline modeling and adjustment
  "purrr",       # Package for functional programming
  "tidyverse",   # Meta-package for data science
  "maps"         # Package for creating maps
)
install.packages(packages[!sapply(packages, requireNamespace, quietly = TRUE)])

# Load required packages for data manipulation and analysis
invisible(sapply(packages, library, character.only = TRUE))

# Set options
knitr::opts_chunk$set(echo = FALSE, message = FALSE)

# Suppress Warnings (This is a me thing, comment this session out to see the conflicting functions)
suppressPackageStartupMessages(library(maps))
```

## FETCHING DATA TO IMPORT

To skip this session, go to the data folder branch of [this repository](https://github.com/airpartners/ambient-summer23/tree/datafolder) to download a pre-made data folder. If you want to modify data/download data for yourself, refer to the below instructions within this session.

### Quant-AQ Data

Refer to the Markdown file API_call.Rmd in this folder. The data should be in ./data/Quant-AQ/MOD-PM/ if nothing goes wrong.

### Meteorology Data

The meteorology data used in some analysis below are taken from the [Iowa Environmental Mesonet](https://mesonet.agron.iastate.edu/request/download.phtml?network=MA_ASOS).

Below are the downloading instructions taken from the [EB Gibson Park Analysis](https://github.com/scott-hersey/EB_AQ_Network/blob/master/Gibson%20Park%20Analysis.Rmd).

Select the following station: \* [BOS] BOSTON/LOGAN INTL

Select the following variables:

-   Temperature (C)

-   Wind Direction

-   Wind Speed [mph]

Select the date range: `7/1/2022 to 2/28/2022` (this dataset is not inclusive of the last date)

Select this timezone: `America/New_York`

Use the following download options: `comma delimited` ,

`no latitude/longitude vectors` ,

`no elevation` ,

`represent missing data with blank string` ,

`denote trace with blank string`

## IMPORT DATA AND PRE-PROCESSING

### Quant-AQ Data

```{r}
library(data.table)
library(lubridate)
library(fs)

start_date <- ymd("2022-07-01")  # Start date of the time range
end_date <- ymd("2023-02-28")    # End date of the time range

process_sensor <- function(sensor_id) {
  file_name <- paste0("./data/Quant-AQ/MOD-PM/", sensor_id, ".csv")
  output_folder <- paste0("./data/Quant-AQ/MOD-PM/broken-down/", sensor_id)
  dir.create(output_folder, recursive = TRUE, showWarnings = FALSE)
  
  # Read the CSV file into a data.table, handle parsing errors
  tryCatch({
    data <- fread(file_name, data.table = FALSE)
  }, error = function(e) {
    message("Error reading ", file_name, ": ", conditionMessage(e))
    return()
  })
  
  # Convert timestamp_local column to datetime
  data$timestamp_local <- ymd_hms(data$timestamp_local)
  
  # Filter data within the specified time range
  filtered_data <- data[data$timestamp_local >= start_date & data$timestamp_local <= end_date, ]
  
  # Create a separate CSV file for each month
  monthly_data <- split(filtered_data, format(filtered_data$timestamp_local, "%Y-%m"))
  
  for (month in names(monthly_data)) {
    month_data <- monthly_data[[month]]
    month_file_path <- file.path(output_folder, paste0(sensor_id, "-", month, ".csv"))
    write.csv(month_data, month_file_path, row.names = FALSE)
  }
}

device_ids <- c(
  "MOD-00024",
  "MOD-00025",
  "MOD-00026",
  "MOD-00027",
  "MOD-00028",
  "MOD-PM-00141",
  "MOD-PM-00211",
  "MOD-PM-00212",
  "MOD-PM-00213",
  "MOD-PM-00214",
  "MOD-PM-00216",
  "MOD-PM-00217",
  "MOD-PM-00221",
  "MOD-PM-00222",
  "MOD-PM-00224",
  "MOD-PM-00226",
  "MOD-PM-00230",
  "MOD-PM-00231"
)

for (sensor_id in device_ids) {
  process_sensor(sensor_id)
}
```

```{r}
library(data.table)
library(lubridate)
library(fs)

start_date <- ymd("2022-07-01")  # Start date of the time range
end_date <- ymd("2023-02-28")    # End date of the time range

file_name <- "./data/metdata.csv"
output_folder <- "./data/Metdata/"
dir.create(output_folder, showWarnings = FALSE)

# Read the CSV file into a data.table, handle parsing errors
tryCatch({
  data <- fread(file_name, data.table = FALSE)
}, error = function(e) {
  message("Error reading ", file_name, ": ", conditionMessage(e))
  return()
})

# Parse the date-time format explicitly
data$valid <- parse_date_time(data$valid, orders = "ymd HMS", truncated = 6)

# Filter data within the specified time range
filtered_data <-
  data[data$valid >= start_date &
         data$valid <= end_date,]

# Create a separate CSV file for each month
monthly_data <-
  split(filtered_data,
        format(filtered_data$valid, "%Y-%m"))

for (month in names(monthly_data)) {
  month_data <- monthly_data[[month]]
  month_file_path <-
    file.path(output_folder, paste0("metdata-", month, ".csv"))
  write.csv(month_data, month_file_path, row.names = FALSE)
}
```