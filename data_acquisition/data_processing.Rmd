---
title: "Data Processing"
author: "Cherry Pham"
date: "2023-07-17"
output: html_document
editor_options: 
  markdown: 
    wrap: 72
---

This document primarily focuses on importing, merging, and
pre-processing the data to prepare it for further analysis. The result
of this function is a data frame containing sensor data that you can use
for plotting.

Follow the **FETCHING DATA TO IMPORT** session to retrieve the data
required to use this document. Pressing `Ctrl + Alt + R` (run all) for
this markdown file would results in a `graphableData.RData` file being
created and saved into the data folder.

The result of this file contains the data frame `mod_met` that can be
used to graph, to visualize this data frame, simply load it by running
the print function commented below:

```{r}
# load("../data/graphableData.RData")
# print(mod_met)
```

To understand and modify the below code, see the **FILE GUIDE** session
below.

## FILE GUIDE

A. **INITIAL SETTINGS**

-   Install and load required R packages and set knit options

B. **FETCHING DATA TO IMPORT**

-   As stated before, in order to run this markdown file, you need a few
    file pre-requisites fulfilled. The instructions to retrieve them is
    found in this session.

C. **IMPORT DATA AND PRE-PROCESSING**

1.  Quant-AQ Data

-   Import data from .csv files by columns, clean up names, add
    latitude, longitude, site names, cleaned data, and store in the data
    frame `mod`
-   `Ctrl + F` "(time range change)" to change the date range of the
    files to read. There are 2 separate occurrences - for modPM and
    modulair.

2.  Meteorology Data

-   Import data from all .csv files in the `Metdata` folder, clean data,
    and store in the data frame `metdata`

D. **DATA PROCESSING**

1.  Merging Datasets: Time sync and merge the Quant-AQ and Meteorology
    datasets

2.  Cleaning Up and Save the Work Space: I think the name is pretty
    descriptive

3.  Sanity Checks: Optional commented out code that you can use to test
    if the code above is working correctly

## INITAL SETTINGS

```{r setup, include=FALSE}
# Check and install required packages if necessary
packages <- c("lubridate", "dplyr", "purrr", "tidyverse", "readr")
install.packages(packages[!sapply(packages, requireNamespace, quietly = TRUE)])

# Load required packages for data manipulation and analysis
invisible(sapply(packages, library, character.only = TRUE))

# Set options
knitr::opts_chunk$set(echo = FALSE, message = FALSE)
```

## FETCHING DATA TO IMPORT

In order for this markdown file to function, you need all your Quant-AQ
and Meteorology data downloaded as csv. This data should also be already
broken down into monthly csv files for both cases. To skip this session
(or this entire data acquisition step), go to the data folder branch of
[this
repository](https://github.com/airpartners/ambient-summer23/tree/datafolder)
to download a pre-made data folder. If you want to modify data/download
data for yourself, refer to the below instructions within this session.

### Quant-AQ Data

Refer to the Markdown file `API_call.Rmd` in this folder.

### Meteorology Data

The meteorology data used in our analysis is taken from [Iowa
Environmental
Mesonet](https://mesonet.agron.iastate.edu/request/download.phtml?network=MA_ASOS).

Below are the downloading instructions taken from the [EB Gibson Park
Analysis](https://github.com/scott-hersey/EB_AQ_Network/blob/master/Gibson%20Park%20Analysis.Rmd).

-   Select the following station: \* [BOS] BOSTON/LOGAN INTL

-   Select the following variables:

    -   Temperature (C)

    -   Wind Direction

    -   Wind Speed [mph]

-   Select the date range: `7/1/2022 to 8/1/2023` (this dataset is not
    inclusive of the last date)

-   Select this timezone: `America/New_York`

-   Use the following download options:

    -   `comma delimited`

    -   `no latitude/longitude vectors`

    -   `no elevation`

    -   `represent missing data with blank string`

    -   `denote trace with blank string`

After retrieving the data, go to
`ambient-summer23/data_acquisition/data_breakdown.Rmd` and run the first
and third code blocks to break the meteorology data down by monthly
`.csv` files.

## IMPORT DATA AND PRE-PROCESSING

### Quant-AQ Data

Change the time range if you only want to break down data from a
specific time range (to optimize speed). `Ctrl + F` the following: (time
range change).

```{r}
# Specify the columns to read
modPM_cols <- c("pm1", "pm25", "pm10", "opcbin0", "opcbin1", "opcbin2", "opcbin3", "opcbin4", "opcbin5", "opcbin6", "opcbin7", "opcbin8", "opcbin9", "opcbin10", "opcbin11", "opcbin12", "opcbin13", "opcbin14", "opcbin15", "opcbin16", "opcbin17", "timestamp_local", "sn.x", "timestamp.x")

modulair_cols <- c("pm1", "pm25", "pm10", "co", "no", "no2", "o3", "opc.bin0", "opc.bin1", "opc.bin2", "opc.bin3", "opc.bin4", "opc.bin5", "opc.bin6", "opc.bin7", "opc.bin8", "opc.bin9", "opc.bin10","opc.bin11", "opc.bin12", "opc.bin13", "opc.bin14", "opc.bin15", "opc.bin16", "opc.bin17", "timestamp_local", "sn.x", "timestamp.x")

# Read in modPM devices' data
modPM_devices <- c(
  "MOD-PM-00141",
  "MOD-PM-00211",
  "MOD-PM-00212",
  "MOD-PM-00213",
  "MOD-PM-00214",
  "MOD-PM-00216",
  "MOD-PM-00217",
  "MOD-PM-00221",
  "MOD-PM-00222",
  "MOD-PM-00224",
  "MOD-PM-00226",
  "MOD-PM-00230",
  "MOD-PM-00231"
)

modPM <- suppressMessages({
  data <- modPM_devices %>%
    map_dfr(function(modPM_device) {
      paths <- c(
        # Taking data from 07/2022 - 07/2023 (time range change)
        sprintf(
          "../data/QuantAQ/MODPM/brokenDown/%s/%s-2022-%02d.csv",
          modPM_device, modPM_device, 7:12
        ),
        sprintf(
          "../data/QuantAQ/MODPM/brokenDown/%s/%s-2023-%02d.csv",
          modPM_device, modPM_device, 1:7
        )
      )
      map_dfr(paths, function(path) {
        suppressWarnings(
          tryCatch(
            read_csv(path, col_select = modPM_cols),
            error = function(e) NULL
          )
        )
      })
    })
})

# Read in modulair devices' data
modulair_devices <- c(
  "MOD-00024",
  "MOD-00025",
  "MOD-00026",
  "MOD-00027",
  "MOD-00028"
)

modulair <- suppressMessages({
  data <- modulair_devices %>%
    map_dfr(function(modulair_device) {
      paths <- c(
        # Taking data from 07/2022 - 02/2023 (time range change)
        sprintf(
          "../data/QuantAQ/MODPM/brokenDown/%s/%s-2022-%02d.csv",
          modulair_device, modulair_device, 7:12
        ),
        sprintf(
          "../data/QuantAQ/MOD-PM/brokenDown/%s/%s-2023-%02d.csv",
          modulair_device, modulair_device, 1:7
        )
      )
      map_dfr(paths, function(path) {
        suppressWarnings(
          tryCatch(
            read_csv(path, col_select = modulair_cols),
            error = function(e) NULL
          )
        )
      })
    })
})

# Bind the 2 datasets
mod <- bind_rows(modulair, modPM)
print(mod)
```

```{r}
# Merging the bins in modPM and modulair data
for (i in 0:17) {
  bin_name <- paste0("bin", i)
  opc_col_name <- paste0("opc.bin", i)
  opcbin_col_name <- paste0("opcbin", i)
  
  mod <- mod %>%
    mutate(!!sym(bin_name) := ifelse(
      !is.na(!!sym(opc_col_name)),
      !!sym(opc_col_name),
      !!sym(opcbin_col_name)
    ))
}

# Print the updated data frame
print(mod)
```

```{r}
# Rename to match manually downloaded datasets
# Comment this out if it errors out because the name is already correct
mod <- mod %>%
  rename(timestamp = timestamp.x, sn = sn.x)

# Combine PM1 bins
mod$pm1num <- mod$bin0 + mod$bin1 + mod$bin2

# Add a formatted date column
mod$date <- as.POSIXct(strptime(mod$timestamp_local, format = "%Y-%m-%d %H:%M:%S", tz = "America/New_York"))

mod <- mod %>%
  select(-matches("^opc\\.bin\\d+$"), -matches("^opcbin\\d+$"))

print(mod)
```

```{r}
# Define the latitude and longitude values for each sensor
sn_lat <- c(
  "MOD-00024" = 42.33155829160215, "MOD-00025" = 42.32862119,
  "MOD-00026" = 42.325756, "MOD-00027" = 42.32012,
  "MOD-00028" = 42.3289, "MOD-PM-00141" = 42.3328,
  "MOD-PM-00211" = 42.3207, "MOD-PM-00212" = 42.326244,
  "MOD-PM-00213" = 42.3145978, "MOD-PM-00214" = 42.315932,
  "MOD-PM-00216" = 42.3294, "MOD-PM-00217" = 42.32355,
  "MOD-PM-00221" = 42.312182, "MOD-PM-00222" = 42.331,
  "MOD-PM-00224" = 42.32012, "MOD-PM-00226" = 42.3226,
  "MOD-PM-00230" = 42.3199, "MOD-PM-00231" = 42.3161
)

sn_lon <- c(
  "MOD-00024" = -71.08360367349657, "MOD-00025" = -71.086748391,
  "MOD-00026" = -71.068577, "MOD-00027" = -71.0679,
  "MOD-00028" = -71.0815, "MOD-PM-00141" = -71.097597,
  "MOD-PM-00211" = -71.0715, "MOD-PM-00212" = -71.081156,
  "MOD-PM-00213" = -71.0971196, "MOD-PM-00214" = -71.087439,
  "MOD-PM-00216" = -71.0777, "MOD-PM-00217" = -71.08866,
  "MOD-PM-00221" = -71.071364, "MOD-PM-00222" = -71.086,
  "MOD-PM-00224" = -71.0679, "MOD-PM-00226" = -71.0738,
  "MOD-PM-00230" = -71.0752, "MOD-PM-00231" = -71.0780
)

# Define the site names for each sensor
sn_sitename <- c(
  "MOD-00024" = "ACE Parking Lot", "MOD-00025" = "Hale Elem",
  "MOD-00026" = "The Base", "MOD-00027" = "Indigo Block",
  "MOD-00028" = "Hibernian Playgr.", "MOD-PM-00141" = "Tobin Comm Ctr",
  "MOD-PM-00211" = "Dudley Vil Playgr", "MOD-PM-00212" = "Dearborn Academy",
  "MOD-PM-00213" = "Rafael Hernandez", "MOD-PM-00214" = "Trotter Elem",
  "MOD-PM-00216" = "Orchard Gardens", "MOD-PM-00217" = "Residence Obierne Pl.",
  "MOD-PM-00221" = "Residence Baker Ave.", "MOD-PM-00222" = "Beryl Gardens",
  "MOD-PM-00224" = "Indigo Block", "MOD-PM-00226" = "Dudley Greenhouse",
  "MOD-PM-00230" = "Trina Persad Playgr", "MOD-PM-00231" = "Cardinal Medeiros"
)

# Add "lat", "lon", "sitename" columns to the existing data frame
mod$lat <- sn_lat[mod$sn]
mod$lon <- sn_lon[mod$sn]
mod$sitename <- sn_sitename[mod$sn]

print(mod)
```

### Meteorology Data

```{r}
# Import meteorology file
metdata <- suppressMessages({
  list.files(path = "../data/Metdata/brokenDown/",
             pattern = "*.csv", 
             full.names = TRUE) %>%
    purrr::map_dfr(read.csv)
})

print(metdata)

# Setting datetime, using correct timezone on East Coast Local time
metdata$date <- as.POSIXct(metdata$valid, format = "%Y-%m-%d %H:%M", tz = "America/New_York")

metdata <- metdata %>%
  rename(wd = drct, ws = sped, original_met_time = valid) %>%
  na.omit(date) %>%
  complete(date = seq(from = min(date), to= max(date),  by = "1 min")) %>%
  fill(c(wd, ws, tmpc)) #fill those new 1 minute interval rows

metdata$ws <- metdata$ws * (1609/3600) #converting to m/s, 1609 meters per mile, 3600 seconds per hr
metdata[,c("station")] <- list(NULL) #getting rid of unnecessary variables
metdata <- unique(metdata) #remove duplicates

print(metdata)
```

## DATA PROCESSING

### Merging Datasets

```{r}
# Time sync met and pollution data
mod$mod_date_1min <- lubridate::round_date(mod$date, unit = "minute")
metdata$met_date_1min <- lubridate::round_date(metdata$date, unit = "minute")

# Merge the two datasets
mod_met <- dplyr::left_join(mod, metdata, by = c("mod_date_1min" = "met_date_1min"))
mod_met$date <- mod_met$date.x

# Delete unnecessary columns created from merging mod and metdata
mod_met <- subset(mod_met, select = -c(date.x, date.y))
```

### Cleaning Up and Save the Work Space

```{r}
# Remove all objects except the final data frame
rm(list = setdiff(ls(), "mod_met"))

# Save environment to graphableData.RData
save.image("../data/graphableData.RData")
```

### Sanity Checks

```{r}
# # Uncomment to test timeVar plots
# # Feel free to add any additional tests
# library(openair)
# 
# print(mod_met)
# openair::timeVariation(mod_met, pollutant = c("ws", "wd", "tmpc"), normalise = TRUE)
```
